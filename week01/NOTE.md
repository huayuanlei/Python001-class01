**本周心得**
1、通过requests库编写爬虫代码，
用bs4或lxml解析，这两种方式都已经掌握了。
不太熟练，还需要多加练习。

2、scrapy库还不熟悉，似懂非懂的状态。
但是我的环境有问题，脚本未运行成功。
vscode用的本地环境、pycharm用的anaconda环境。

3、第二个作业（用scrapy爬取数据）我没有运行成功，
只是根据老师讲的内容，自己写的。

**本周笔记：**
爬虫命令行语句
1、创建项目
scrapy startproject new_name

2、创建具体的爬虫
scrapy genspider movies douban.com

3、运行爬虫
scrapy crawl new_name